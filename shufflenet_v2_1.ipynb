{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8a4a768",
   "metadata": {},
   "source": [
    "## Library Imports and Environment Setup\n",
    "\n",
    "**Purpose**: Initialize all required dependencies for the multi-label image classification pipeline.\n",
    "\n",
    "**Key Components**:\n",
    "- **PyTorch ecosystem**: Core deep learning framework chosen for its dynamic computation graph, extensive model zoo, and CUDA optimization\n",
    "- **torchvision.models**: Provides pre-trained ShuffleNet V2 with ImageNet weights for transfer learning\n",
    "- **Custom dataset module**: Classes are imported from `dataset.py` instead of being defined inline - this is **critical for Windows multiprocessing support** in DataLoader, as Windows uses spawn instead of fork for process creation\n",
    "- **TensorBoard integration**: Real-time training visualization via SummaryWriter for monitoring convergence and detecting anomalies\n",
    "\n",
    "**Design Rationale**: Separating dataset classes into a standalone Python module resolves Windows-specific pickling issues when using `num_workers > 0` in DataLoader, enabling parallel data loading for faster training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9094f777-f1c1-4224-b248-3a044861fca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully\n",
      "PyTorch version: 2.5.1\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# import statements for python, torch and companion libraries and your own modules\n",
    "import os\n",
    "import sys\n",
    "#nb_dir = os.path.split(os.getcwd())[0]\n",
    "#if nb_dir not in sys.path:\n",
    "    #sys.path.append(nb_dir)\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "\n",
    "#from lion_pytorch import Lion\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import shufflenet_v2_x1_0, ShuffleNet_V2_X1_0_Weights\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Import dataset classes from dataset.py for Windows multiprocessing support\n",
    "from dataset import COCOTrainImageDataset, COCOTestImageDataset, ValidationDataset\n",
    "\n",
    "print(\"All libraries imported successfully\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6177cf30",
   "metadata": {},
   "source": [
    "## Reproducibility Configuration\n",
    "\n",
    "**Purpose**: Establish deterministic behavior across training runs for result reproducibility.\n",
    "\n",
    "**Technical Details**:\n",
    "- **Fixed random seeds (42)**: Ensures identical weight initialization and data shuffling across experiments for reproducible results\n",
    "- **cuDNN settings**:\n",
    "  - `deterministic=False`: Prioritizes computational performance, as cuDNN can select fastest algorithms\n",
    "  - `benchmark=True`: Enables cuDNN autotuner to benchmark and select optimal convolution algorithms for the fixed input size (224Ã—224), providing ~10-30% speedup\n",
    "\n",
    "**Rationale**: The seeded initialization ensures consistent starting conditions for fair model comparison, while cuDNN optimization maximizes training efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7286f114-09ea-4ea1-88d3-362671cb0cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = False  \n",
    "    torch.backends.cudnn.benchmark = True  \n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dd44f2",
   "metadata": {},
   "source": [
    "## Hyperparameter Configuration\n",
    "\n",
    "**Purpose**: Define training hyperparameters optimized for multi-label classification on COCO dataset.\n",
    "\n",
    "**Key Hyperparameters**:\n",
    "- **Batch size (128)**: Larger batch size enables more stable gradient estimates and better GPU utilization, allowing for slightly higher learning rates through linear scaling rule\n",
    "- **Learning rate (4e-4)**: Scaled from base 3e-4 for efficient convergence within 20 epochs, suitable for fine-tuning the lightweight ShuffleNet architecture on COCO\n",
    "- **Weight decay (5e-5)**: Moderate L2 regularization strength provides effective generalization on 65K training samples without over-constraining model capacity\n",
    "- **Threshold (0.5)**: Standard probability cutoff for binary classification per label, balanced for precision-recall trade-off\n",
    "\n",
    "**Model Selection Metric**:\n",
    "- **Validation Loss**: Direct optimization target that provides stable and reliable checkpointing, ensuring the saved model represents the best generalization performance\n",
    "\n",
    "**Validation Split**: 10% holdout ensures sufficient data for reliable performance estimation while preserving ~59K samples for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d39e4257-d696-4a4b-ba57-dfb209dba058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global variables and hyperparameters defined:\n",
      "  - Batch size: 128\n",
      "  - Number of epochs: 20\n",
      "  - Learning rate: 0.0003\n",
      "  - Validation split: 0.1\n",
      "  - Threshold: 0.5\n",
      "  - Model selection metric: val_loss\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# global variables defining training hyper-parameters among other things \n",
    "BATCH_SIZE = 128  \n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 3e-4  \n",
    "WEIGHT_DECAY = 5e-5\n",
    "NUM_CLASSES = 80\n",
    "VALIDATION_SPLIT = 0.1\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "\n",
    "# Options: 'val_loss', 'micro_f1', 'macro_f1', 'mAP'\n",
    "METRIC_OPTION = 'val_loss'  \n",
    "\n",
    "print(\"Global variables and hyperparameters defined:\")\n",
    "print(f\"  - Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  - Number of epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  - Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  - Validation split: {VALIDATION_SPLIT}\")\n",
    "print(f\"  - Threshold: {THRESHOLD}\")\n",
    "print(f\"  - Model selection metric: {METRIC_OPTION}\")\n",
    "\n",
    "# device initialization\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b31cd1d-5acf-4cd8-8dde-49409a28d52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data directories initialization\n",
    "DATA_DIR = \"ms-coco\"\n",
    "TRAIN_IMG_DIR = os.path.join(DATA_DIR, \"images\", \"train-resized\", \"train-resized\")\n",
    "TEST_IMG_DIR = os.path.join(DATA_DIR, \"images\", \"test-resized\", \"test-resized\")\n",
    "TRAIN_LABELS_DIR = os.path.join(DATA_DIR, \"labels\", \"train\")\n",
    "MODEL_SAVE_PATH = \"best_coco_shuffle_model.pth\"\n",
    "OUTPUT_JSON_FILE = \"coco_predictions_shuffle_v9.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e83bf0",
   "metadata": {},
   "source": [
    "## Dataset Path Configuration\n",
    "\n",
    "**Purpose**: Define directory paths for dataset access and output artifacts.\n",
    "\n",
    "**Structure**:\n",
    "- **Images**: Pre-resized to reduce I/O overhead during training\n",
    "- **Labels**: `.cls` annotation files containing class indices per image\n",
    "- **Output**: Model checkpoint and JSON prediction file for submission\n",
    "\n",
    "**Note**: Paths follow the expected MS-COCO challenge directory structure with train/test splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d64c5467-88d4-4ab5-b910-9a8d9650fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class definitions\n",
    "classes = (\"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\", \n",
    "           \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\",\n",
    "           \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\",       \n",
    "           \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
    "           \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n",
    "           \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\", \n",
    "           \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \n",
    "           \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \n",
    "           \"hair drier\", \"toothbrush\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cb6112",
   "metadata": {},
   "source": [
    "## Class Label Definitions\n",
    "\n",
    "**Purpose**: Define the 80-class taxonomy from MS-COCO dataset in canonical order.\n",
    "\n",
    "**Rationale**: Maintaining the official COCO class ordering ensures label correspondence with ground truth annotations and enables direct comparison with baseline methods. These classes span diverse object categories including people, vehicles, animals, furniture, and everyday objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "377a65a4-12c8-4855-bc63-32c78e291553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directories and class names defined:\n",
      "  - Training images: ms-coco\\images\\train-resized\\train-resized\n",
      "  - Test images: ms-coco\\images\\test-resized\\test-resized\n",
      "  - Training labels: ms-coco\\labels\\train\n",
      "  - Dataset contains 80 classes\n"
     ]
    }
   ],
   "source": [
    "print(\"Data directories and class names defined:\")\n",
    "print(f\"  - Training images: {TRAIN_IMG_DIR}\")\n",
    "print(f\"  - Test images: {TEST_IMG_DIR}\")\n",
    "print(f\"  - Training labels: {TRAIN_LABELS_DIR}\")\n",
    "print(f\"  - Dataset contains {NUM_CLASSES} classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae905931",
   "metadata": {},
   "source": [
    "## Dataset Class Import Confirmation\n",
    "\n",
    "**Purpose**: Verify that custom Dataset classes are properly imported from external module.\n",
    "\n",
    "**Windows-Specific Requirement**: PyTorch's DataLoader with multiprocessing on Windows requires Dataset classes to be importable from a separate `.py` file (not notebook-defined) to enable proper serialization via pickle protocol. This message confirms the architecture follows Windows best practices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca2d4de6-7658-42e9-bdc3-6d27c95aadc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Full training dataset size: 65000\n",
      "Training set size: 58500\n",
      "Validation set size: 6500\n"
     ]
    }
   ],
   "source": [
    "# instantiation of transforms, datasets and data loaders\n",
    "# TIP : use torch.utils.data.random_split to split the training set into train and validation subsets\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.BILINEAR),   \n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create full training dataset\n",
    "print(\"Loading dataset...\")\n",
    "full_train_dataset = COCOTrainImageDataset(\n",
    "    img_dir=TRAIN_IMG_DIR,\n",
    "    annotations_dir=TRAIN_LABELS_DIR,\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "print(f\"Full training dataset size: {len(full_train_dataset)}\")\n",
    "\n",
    "# Split training data into train and validation subsets using torch.utils.data.random_split\n",
    "train_size = int((1 - VALIDATION_SPLIT) * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_train_dataset, \n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124122de",
   "metadata": {},
   "source": [
    "## Data Augmentation and Dataset Initialization\n",
    "\n",
    "**Purpose**: Apply transformation pipelines and instantiate dataset objects with train/validation split.\n",
    "\n",
    "**Transformation Strategy**:\n",
    "\n",
    "**Training Augmentations**:\n",
    "- **Resize to 224Ã—224**: Matches ShuffleNet V2 input requirements (standard ImageNet dimensions)\n",
    "- **BILINEAR interpolation**: Smooth resampling preserving edge details better than nearest-neighbor\n",
    "- **RandomHorizontalFlip (p=0.5)**: Introduces horizontal symmetry as data augmentation, effective for object-centric datasets like COCO where orientation variance exists\n",
    "- **ImageNet normalization**: Uses standard mean=[0.485, 0.456, 0.406] and std=[0.229, 0.224, 0.225] to match pre-training statistics, crucial for transfer learning\n",
    "\n",
    "**Validation Transformations**:\n",
    "- **No augmentation**: Only resize and normalize to evaluate model on clean data\n",
    "- Ensures unbiased performance estimation\n",
    "\n",
    "**Dataset Splitting**:\n",
    "- `random_split` with fixed seed partitions 65K samples into 58.5K train / 6.5K validation\n",
    "- Deterministic split enables reproducible experiments\n",
    "\n",
    "**Rationale**: Minimal augmentation strategy reduces training time while preserving sample diversity. More aggressive augmentation (rotation, color jitter) was avoided to maintain COCO's naturalistic image characteristics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59c0b5c2-fe6a-4ca1-9973-bbc1d18351cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaders created successfully with Windows multiprocessing support\n",
      "  - Training loader: 457 batches, 6 workers\n",
      "  - Validation loader: 51 batches, 6 workers\n"
     ]
    }
   ],
   "source": [
    "val_dataset_transformed = ValidationDataset(val_dataset, val_transforms)\n",
    "\n",
    "# Create data loaders with Windows-compatible multiprocessing settings\n",
    "# For Windows, we can now use num_workers > 0 since dataset classes are in separate .py file\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=6,  \n",
    "    pin_memory=True,  \n",
    "    drop_last=True,\n",
    "    persistent_workers=True  # Keep workers alive between epochs\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset_transformed, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=6,  \n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "print(\"Data loaders created successfully with Windows multiprocessing support\")\n",
    "print(f\"  - Training loader: {len(train_loader)} batches, {train_loader.num_workers} workers\")\n",
    "print(f\"  - Validation loader: {len(val_loader)} batches, {val_loader.num_workers} workers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b51e45",
   "metadata": {},
   "source": [
    "## Validation Dataset Wrapper\n",
    "\n",
    "**Purpose**: Apply validation-specific transforms to the validation subset.\n",
    "\n",
    "**Implementation Detail**: The `ValidationDataset` wrapper re-applies transforms because `random_split` creates subset views that inherit the original dataset's transformations. This wrapper ensures validation data uses the non-augmented transform pipeline (no flipping) for accurate evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d622796",
   "metadata": {},
   "source": [
    "## Model Architecture Definition\n",
    "\n",
    "**Purpose**: Define custom multi-label classifier based on ShuffleNet V2 backbone.\n",
    "\n",
    "**Architecture Rationale**:\n",
    "\n",
    "**Backbone Choice - ShuffleNet V2 x1.0**:\n",
    "- **Efficiency-oriented**: Designed for mobile/edge devices with only ~2.3M parameters, enabling fast training and inference\n",
    "- **Optimal FLOPs-accuracy trade-off**: Achieves competitive accuracy at ~150 MFLOPs (10Ã— faster than ResNet-50)\n",
    "- **Channel shuffle mechanism**: Enables efficient cross-group information exchange without expensive 1Ã—1 convolutions\n",
    "- **Pre-trained on ImageNet**: Provides strong initial feature extractors for transfer learning\n",
    "- **COCO training experience**: ShuffleNet has been successfully trained on COCO dataset in prior work, demonstrating its effectiveness for multi-label object classification tasks\n",
    "- **Compact model size**: The relatively small parameter count (~1.8M) allows for more transparent observation of how each fine-tuning operation affects model performance, making it ideal for experimental analysis and hyperparameter tuning\n",
    "\n",
    "**Classification Head Design**:\n",
    "- **Dropout layers (0.3, 0.2)**: Stochastic regularization with graduated dropout rates - higher in first layer where features are more task-specific, lower before final classification\n",
    "- **Intermediate 512-dim layer**: Provides sufficient capacity for learning complex multi-label patterns while maintaining parameter efficiency\n",
    "- **ReLU activation**: Standard non-linearity for intermediate representations, enabling effective gradient flow\n",
    "- **Output dimension = 80**: One logit per COCO class for independent multi-label prediction\n",
    "\n",
    "**Multi-Label Formulation**: Unlike single-label classification, no softmax is applied - instead, sigmoid activation (applied later) treats each class independently, enabling multiple simultaneous predictions per image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c22b8d27-dafe-4770-8c34-603330f9df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCOMultiLabelClassifier(nn.Module):\n",
    "    def __init__(self, num_classes: int = 80, pretrained: bool = True):\n",
    "        super(COCOMultiLabelClassifier, self).__init__()\n",
    "        \n",
    "        # Use pre-trained ShuffleNet V2 x1.0 as backbone\n",
    "        if pretrained:\n",
    "            self.backbone = shufflenet_v2_x1_0(weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1)\n",
    "        else:\n",
    "            self.backbone = shufflenet_v2_x1_0(weights=None)\n",
    "        \n",
    "        # ShuffleNet V2 x1.0 has 1024 output features\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        \n",
    "        # Replace classification head with multi-label classification head\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df4cefe",
   "metadata": {},
   "source": [
    "## DataLoader Configuration with Multiprocessing\n",
    "\n",
    "**Purpose**: Create efficient data loading pipelines with parallel prefetching.\n",
    "\n",
    "**Optimization Strategies**:\n",
    "- **num_workers=6**: Spawns 6 background processes for asynchronous data loading, reducing GPU idle time\n",
    "- **pin_memory=True**: Allocates tensors in page-locked memory for faster CPUâ†’GPU transfer via DMA\n",
    "- **persistent_workers=True**: Keeps worker processes alive between epochs, avoiding spawn overhead (significant on Windows)\n",
    "- **drop_last=True** (train only): Ensures consistent batch sizes, preventing batch normalization issues with small final batches\n",
    "\n",
    "**Performance Impact**: These settings typically provide 2-3Ã— speedup compared to single-process loading on modern GPUs, especially critical for small models like ShuffleNet where data loading can become the bottleneck.\n",
    "\n",
    "**Windows Compatibility**: The combination of external dataset module + persistent workers resolves common Windows DataLoader errors while maximizing throughput.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d09d758-7c30-4df4-a2b4-e77c429d372e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "Model loaded to device: cuda\n",
      "  - Total parameters: 1,819,444\n",
      "  - Trainable parameters: 1,819,444\n"
     ]
    }
   ],
   "source": [
    "# instantiation and preparation of network model\n",
    "print(\"Initializing model...\")\n",
    "model = COCOMultiLabelClassifier(num_classes=NUM_CLASSES, pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model loaded to device: {device}\")\n",
    "print(f\"  - Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"  - Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22e1cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mAP(predictions, labels):\n",
    "    predictions_np = predictions.cpu().numpy()\n",
    "    labels_np = labels.cpu().numpy()\n",
    "    \n",
    "    aps = []\n",
    "    for class_idx in range(labels.shape[1]):\n",
    "        y_true = labels_np[:, class_idx]\n",
    "        y_scores = predictions_np[:, class_idx]\n",
    "        \n",
    "        # Skip classes with no positive samples\n",
    "        if y_true.sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        # Sort by prediction scores (descending)\n",
    "        sorted_indices = np.argsort(-y_scores)\n",
    "        y_true_sorted = y_true[sorted_indices]\n",
    "        \n",
    "        # Calculate precision at each threshold\n",
    "        tp = np.cumsum(y_true_sorted)\n",
    "        fp = np.cumsum(1 - y_true_sorted)\n",
    "        \n",
    "        precision = tp / (tp + fp + 1e-8)\n",
    "        \n",
    "        total_positives = y_true.sum()\n",
    "        recall = tp / total_positives\n",
    "        \n",
    "        precision = np.concatenate([[0], precision, [0]])\n",
    "        recall = np.concatenate([[0], recall, [1]])\n",
    "        \n",
    "        for i in range(len(precision) - 2, -1, -1):\n",
    "            precision[i] = max(precision[i], precision[i + 1])\n",
    "        \n",
    "        ap = np.sum((recall[1:] - recall[:-1]) * precision[1:])\n",
    "        aps.append(ap)\n",
    "    \n",
    "    if len(aps) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    mAP = np.mean(aps)\n",
    "    return float(mAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b676b29c",
   "metadata": {},
   "source": [
    "## Model Architecture Definition\n",
    "\n",
    "**Purpose**: Define custom multi-label classifier based on ShuffleNet V2 backbone.\n",
    "\n",
    "**Architecture Rationale**:\n",
    "\n",
    "**Backbone Choice - ShuffleNet V2 x1.0**:\n",
    "- **Efficiency-oriented**: Designed for mobile/edge devices with only ~2.3M parameters, enabling fast training and inference\n",
    "- **Optimal FLOPs-accuracy trade-off**: Achieves competitive accuracy at ~150 MFLOPs (10Ã— faster than ResNet-50)\n",
    "- **Channel shuffle mechanism**: Enables efficient cross-group information exchange without expensive 1Ã—1 convolutions\n",
    "- **Pre-trained on ImageNet**: Provides strong initial feature extractors for transfer learning\n",
    "- **COCO training experience**: ShuffleNet has been successfully trained on COCO dataset in prior work, demonstrating its effectiveness for multi-label object classification tasks\n",
    "- **Compact model size**: The relatively small parameter count (~1.8M) allows for more transparent observation of how each fine-tuning operation affects model performance, making it ideal for experimental analysis and hyperparameter tuning\n",
    "\n",
    "**Classification Head Design**:\n",
    "- **Dropout layers (0.3, 0.2)**: Stochastic regularization with graduated dropout rates - higher in first layer where features are more task-specific, lower before final classification\n",
    "- **Intermediate 512-dim layer**: Provides sufficient capacity for learning complex multi-label patterns while maintaining parameter efficiency\n",
    "- **ReLU activation**: Standard non-linearity for intermediate representations, enabling effective gradient flow\n",
    "- **Output dimension = 80**: One logit per COCO class for independent multi-label prediction\n",
    "\n",
    "**Multi-Label Formulation**: Unlike single-label classification, no softmax is applied - instead, sigmoid activation (applied later) treats each class independently, enabling multiple simultaneous predictions per image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e22549af-61ff-4797-9526-0e8851ba54d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for select the best model\n",
    "def calculate_f1_metrics(predictions, labels, threshold=0.5):\n",
    "\n",
    "    predictions_binary = (predictions > threshold).float()\n",
    "    tp = (predictions_binary * labels).sum()\n",
    "    fp = (predictions_binary * (1 - labels)).sum() \n",
    "    fn = ((1 - predictions_binary) * labels).sum()\n",
    "    \n",
    "    micro_precision = tp / (tp + fp + 1e-8)\n",
    "    micro_recall = tp / (tp + fn + 1e-8)\n",
    "    micro_f1 = 2 * micro_precision * micro_recall / (micro_precision + micro_recall + 1e-8)\n",
    "    \n",
    "    class_f1s = []\n",
    "    for c in range(labels.shape[1]):\n",
    "        tp_c = (predictions_binary[:, c] * labels[:, c]).sum()\n",
    "        fp_c = (predictions_binary[:, c] * (1 - labels[:, c])).sum()\n",
    "        fn_c = ((1 - predictions_binary[:, c]) * labels[:, c]).sum()\n",
    "        \n",
    "        prec_c = tp_c / (tp_c + fp_c + 1e-8)\n",
    "        rec_c = tp_c / (tp_c + fn_c + 1e-8)\n",
    "        f1_c = 2 * prec_c * rec_c / (prec_c + rec_c + 1e-8)\n",
    "        class_f1s.append(f1_c)\n",
    "    \n",
    "    macro_f1 = torch.stack(class_f1s).mean()\n",
    "    return float(micro_f1), float(macro_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cced7d",
   "metadata": {},
   "source": [
    "## Model Instantiation and Device Placement\n",
    "\n",
    "**Purpose**: Initialize model with pre-trained weights and move to GPU.\n",
    "\n",
    "**Key Steps**:\n",
    "- **pretrained=True**: Loads ImageNet-1K weights for the backbone layers, providing strong initial feature representations adapted from large-scale ImageNet training\n",
    "- **Device placement**: Transfers all parameters to CUDA for GPU-accelerated training\n",
    "- **Parameter statistics**: 1.8M total parameters all set to trainable for full fine-tuning capability\n",
    "\n",
    "**Fine-Tuning Strategy**: Training all layers enables the backbone to adapt its generic ImageNet features to COCO's specific visual patterns and multi-label classification requirements, maximizing model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484ab2aa",
   "metadata": {},
   "source": [
    "## Test Set Inference Loop\n",
    "\n",
    "**Purpose**: Generate predictions for all test images and populate results dictionary.\n",
    "\n",
    "**Inference Pipeline**:\n",
    "1. **Gradient-free computation**: `torch.no_grad()` disables gradient calculation, reducing memory consumption and accelerating inference\n",
    "2. **Forward pass**: Compute raw logits from trained model\n",
    "3. **Sigmoid activation**: Convert logits to class probabilities in range [0, 1] for independent multi-label predictions\n",
    "4. **Thresholding**: Apply 0.5 cutoff to convert probabilities to binary predictions\n",
    "5. **Class extraction**: Collect indices of all positive predictions for each image\n",
    "6. **Dictionary population**: Store predicted class index lists keyed by filename for JSON output\n",
    "\n",
    "**Prediction Format**: Each image filename is mapped to a list of class indices (e.g., `[0, 2, 5, ...]`) representing all detected object categories.\n",
    "\n",
    "**Processing**: Successfully processes all 4952 test images through the inference pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d1bf3d5-fb71-4fb7-8610-8167335f49de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(train_loader: DataLoader, net: nn.Module, criterion: nn.Module, \n",
    "               optimizer: optim.Optimizer, device: torch.device) -> float:\n",
    "\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\",position=0, leave=True):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04f9915",
   "metadata": {},
   "source": [
    "## JSON Output and Verification\n",
    "\n",
    "**Purpose**: Serialize predictions to JSON file for challenge submission.\n",
    "\n",
    "**Output Process**:\n",
    "1. **Sample inspection**: Display first 5 predictions for verification of prediction format and quality\n",
    "2. **JSON serialization**: Write dictionary with indent=2 for human-readable formatting\n",
    "3. **File size verification**: Confirm output file size is reasonable for 4952 image predictions\n",
    "4. **Error handling**: Graceful exception handling ensures any serialization issues are caught and reported\n",
    "\n",
    "**Output Format**: JSON file maps each test image filename to its predicted class index list, following COCO challenge submission requirements.\n",
    "\n",
    "**Submission Ready**: Output format matches official COCO challenge specification (filename â†’ class_indices mapping) for direct submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc67e949",
   "metadata": {},
   "source": [
    "## Mean Average Precision (mAP) Metric Implementation\n",
    "\n",
    "**Purpose**: Implement mAP calculation for multi-label classification evaluation.\n",
    "\n",
    "**Metric Rationale**:\n",
    "- **mAP superiority over F1**: Evaluates ranking quality across all thresholds, not just a single operating point\n",
    "- **Per-class AP calculation**: Measures precision-recall area for each class independently\n",
    "- **Handles class imbalance**: Averaging per-class APs gives equal weight to rare and common classes\n",
    "\n",
    "**Algorithm Details**:\n",
    "1. **Per-class processing**: Iterate through all 80 classes\n",
    "2. **Sort by confidence**: Rank predictions by sigmoid probabilities (descending)\n",
    "3. **Precision-recall curve**: Compute cumulative TP/FP at each threshold\n",
    "4. **Monotonic interpolation**: Ensure precision is non-increasing with recall (standard VOC/COCO protocol)\n",
    "5. **Area under curve**: Integrate using trapezoidal rule\n",
    "6. **Skip empty classes**: Excludes classes with no positive samples from averaging\n",
    "\n",
    "**Technical Considerations**:\n",
    "- **Numerical stability**: Added epsilon (1e-8) prevents division by zero\n",
    "- **Boundary conditions**: Extends curve with (0,0) and (1,0) endpoints for proper area calculation\n",
    "- **COCO alignment**: Implementation follows official COCO evaluation protocol for fair benchmark comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "566f95e5-0e55-482d-91a7-2c97680cf0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loop(val_loader: DataLoader, net: nn.Module, criterion: nn.Module, \n",
    "                   device: torch.device) -> Dict[str, float]:\n",
    "\n",
    "    net.eval()\n",
    "    val_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Validating\",position=0, leave=True):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            batch_loss = criterion(outputs, labels)\n",
    "            val_loss += batch_loss.item() * images.size(0)\n",
    "            \n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            \n",
    "            all_predictions.append(probabilities.cpu())  # save the probabilities instead of predictions\n",
    "            all_labels.append(labels.cpu())\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    all_predictions = torch.cat(all_predictions, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "    micro_f1, macro_f1 = calculate_f1_metrics(all_predictions, all_labels)\n",
    "    mAP = calculate_mAP(all_predictions, all_labels)\n",
    "\n",
    "    predictions_binary = (all_predictions > THRESHOLD).float()\n",
    "    exact_match = (all_predictions == all_labels).all(dim=1).float().mean().item()\n",
    "    \n",
    "    sample_accuracy = ((all_predictions == all_labels).float().mean(dim=1)).mean().item()\n",
    "    \n",
    "    return {\n",
    "        'loss': val_loss,\n",
    "        'exact_match_accuracy': exact_match,\n",
    "        'sample_accuracy': sample_accuracy,\n",
    "        'micro_f1': micro_f1,\n",
    "        'macro_f1': macro_f1,\n",
    "        'mAP': mAP,\n",
    "        'predictions': all_predictions,\n",
    "        'labels': all_labels\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10d38dc",
   "metadata": {},
   "source": [
    "## F1 Score Metrics (Micro and Macro)\n",
    "\n",
    "**Purpose**: Calculate complementary F1 metrics for multi-label performance assessment.\n",
    "\n",
    "**Metric Definitions**:\n",
    "\n",
    "**Micro F1**:\n",
    "- **Global aggregation**: Computes precision/recall from aggregated TP/FP/FN across all classes\n",
    "- **Interpretation**: Overall performance weighted by class frequency\n",
    "- **Bias**: Favors common classes in imbalanced datasets\n",
    "\n",
    "**Macro F1**:\n",
    "- **Per-class averaging**: Computes F1 for each class independently, then averages\n",
    "- **Interpretation**: Treats all classes equally regardless of frequency\n",
    "- **Bias**: Better reflects performance on rare classes\n",
    "\n",
    "**Implementation Details**:\n",
    "- **Threshold application**: Converts probabilities to binary predictions at 0.5 cutoff\n",
    "- **Numerical stability**: Epsilon terms prevent division errors when precision/recall denominators are zero\n",
    "- **Complementary to mAP**: While mAP evaluates ranking, F1 scores assess classification accuracy at a specific threshold\n",
    "\n",
    "**Use Case**: Macro F1 is particularly valuable for COCO's long-tailed distribution where rare objects (e.g., toothbrush, hair dryer) should be weighted equally with common ones (person, car).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d188d0bf",
   "metadata": {},
   "source": [
    "## Loss Function and Optimizer Configuration\n",
    "\n",
    "**Purpose**: Define optimization components for training.\n",
    "\n",
    "**Loss Function - BCEWithLogitsLoss**:\n",
    "- **Standard multi-label loss**: Combines sigmoid activation and binary cross-entropy in a numerically stable single operation\n",
    "- **Numerically stable**: Computes log-sum-exp trick internally to prevent overflow/underflow issues\n",
    "- **Multi-label formulation**: Treats each class independently, computing binary cross-entropy for all 80 classes simultaneously\n",
    "- **Probabilistic gradients**: Provides well-calibrated gradients for learning probability distributions, essential for multi-label classification\n",
    "\n",
    "**Optimizer - AdamW**:\n",
    "- **Adaptive learning rates**: Per-parameter learning rates automatically adjust based on first and second moment estimates of gradients\n",
    "- **Weight decay decoupling**: Applies L2 regularization correctly by decoupling it from gradient-based updates, fixing Adam's implementation flaw\n",
    "- **Fast convergence**: Adaptive method enables efficient convergence within 20 epochs on COCO dataset\n",
    "- **Regularization strength**: 5e-5 weight decay provides effective generalization without over-constraining the model\n",
    "\n",
    "**Learning Rate Scheduler - OneCycleLR**:\n",
    "- **Warmup phase**: Initial 30% of training (pct_start=0.3) gradually increases LR, allowing model to adapt to COCO data before aggressive learning\n",
    "- **Peak learning**: Reaches maximum LR (4e-4) for efficient feature learning in middle epochs\n",
    "- **Annealing phase**: Final 70% gradually decreases LR for fine-grained optimization and stable convergence\n",
    "- **Fast training**: OneCycleLR strategy enables strong performance within limited epoch budget (20 epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7416a826-17e6-40ae-9acf-c2e4e8b6ffbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss criterion initialized: BCEWithLogitsLoss\n",
      "Optimizer and scheduler initialized:\n",
      "  - Optimizer: AdamW\n",
      "  - Learning rate: 0.0003\n",
      "  - Weight decay: 5e-05\n",
      "  - Scheduler: CosineAnnealingLR\n"
     ]
    }
   ],
   "source": [
    "# instantiation of loss criterion\n",
    "# instantiation of optimizer, registration of network parameters\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "#criterion = nn.L1Loss()\n",
    "\n",
    "print(\"Loss criterion initialized: BCEWithLogitsLoss\")\n",
    "#print(\"Loss criterion initialized: L1Loss\")\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=LEARNING_RATE, \n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "'''\n",
    "optimizer = Lion(\n",
    "    model.parameters(),\n",
    "    lr=1e-5,\n",
    "    weight_decay=1e-2\n",
    ")\n",
    "'''\n",
    "\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=LEARNING_RATE,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    pct_start=0.15\n",
    ")\n",
    "\n",
    "'''\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, \n",
    "    T_max=NUM_EPOCHS, \n",
    "    eta_min=1e-6\n",
    ")\n",
    "'''\n",
    "\n",
    "print(\"Optimizer and scheduler initialized:\")\n",
    "print(f\"  - Optimizer: AdamW\")\n",
    "print(f\"  - Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  - Weight decay: {WEIGHT_DECAY}\")\n",
    "print(f\"  - Scheduler: CosineAnnealingLR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fce22e6",
   "metadata": {},
   "source": [
    "## Training Loop Implementation\n",
    "\n",
    "**Purpose**: Execute one epoch of gradient-based optimization.\n",
    "\n",
    "**Training Protocol**:\n",
    "1. **Training mode**: `model.train()` enables dropout and batch normalization training behavior\n",
    "2. **Forward pass**: Compute logits for batch\n",
    "3. **Loss computation**: Calculate multi-label binary cross-entropy loss via BCEWithLogitsLoss\n",
    "4. **Backward pass**: Compute gradients via automatic differentiation\n",
    "5. **Weight update**: Apply AdamW optimizer step with adaptive learning rates\n",
    "6. **Loss accumulation**: Track weighted average across batches\n",
    "\n",
    "**Design Choices**:\n",
    "- **Zero gradients first**: Prevents gradient accumulation from previous iterations, ensuring clean gradient computation\n",
    "- **Batch-weighted averaging**: Multiplies loss by batch size before accumulating to properly weight the final epoch loss\n",
    "- **Progress monitoring**: tqdm provides real-time ETA and throughput metrics for tracking training progress\n",
    "\n",
    "**Return Value**: Average loss per sample for epoch-level monitoring and convergence analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c5e9639-803b-4050-8f93-d1270256e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"runs/coco_multi_label_shuffle\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "#writer = SummaryWriter(log_dir)\n",
    "\n",
    "#print(f\"Logs will be saved to: {log_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dd903e",
   "metadata": {},
   "source": [
    "## Validation Loop with Comprehensive Metrics\n",
    "\n",
    "**Purpose**: Evaluate model on validation set without gradient updates.\n",
    "\n",
    "**Evaluation Protocol**:\n",
    "1. **Evaluation mode**: `model.eval()` disables dropout and uses batch normalization running statistics\n",
    "2. **No gradients**: `torch.no_grad()` reduces memory consumption by not storing intermediate activations\n",
    "3. **Sigmoid activation**: Converts logits to [0,1] probabilities for multi-label prediction\n",
    "4. **Batch accumulation**: Collects predictions and labels in memory for metric computation\n",
    "\n",
    "**Comprehensive Metrics**:\n",
    "- **Loss**: Validation set loss for monitoring overfitting\n",
    "- **Exact match accuracy**: Percentage of samples with all 80 labels predicted correctly (very strict)\n",
    "- **Sample accuracy**: Average per-sample label accuracy (more lenient)\n",
    "- **Micro/Macro F1**: Complementary perspectives on classification performance\n",
    "- **mAP**: Primary ranking metric for model selection\n",
    "\n",
    "**Return Dictionary**: Encapsulates all metrics plus raw predictions/labels for potential post-analysis.\n",
    "\n",
    "**Why return predictions**: Enables threshold tuning or ensemble methods without re-running inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7571322-c64f-4661-b12a-2dc80d37969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_graphs(summary_writer, epoch, train_results, val_results,\n",
    "                  train_class_results=None, val_class_results=None, \n",
    "                  class_names=None, mbatch_group=-1, mbatch_count=0, mbatch_losses=None):\n",
    "    \n",
    "    # Log mini-batch losses if available\n",
    "    if mbatch_group > 0 and mbatch_losses:\n",
    "        for i in range(len(mbatch_losses)):\n",
    "            summary_writer.add_scalar(\"Losses/Train mini-batches\",\n",
    "                                  mbatch_losses[i],\n",
    "                                  epoch * mbatch_count + (i+1)*mbatch_group)\n",
    "\n",
    "    # Log training vs validation losses\n",
    "    summary_writer.add_scalars(\"Losses/Train Loss vs Validation Loss\",\n",
    "                               {\"Train Loss\": train_results[\"loss\"],\n",
    "                                \"Validation Loss\": val_results[\"loss\"]},\n",
    "                               epoch + 1)\n",
    "\n",
    "    # Log F1 scores\n",
    "    summary_writer.add_scalars(\"Metrics/F1 Scores\",\n",
    "                               {\"Train Micro F1\": train_results[\"micro_f1\"],\n",
    "                                \"Validation Micro F1\": val_results[\"micro_f1\"],\n",
    "                                \"Train Macro F1\": train_results[\"macro_f1\"],\n",
    "                                \"Validation Macro F1\": val_results[\"macro_f1\"]},\n",
    "                               epoch + 1)\n",
    "\n",
    "    # Log accuracies\n",
    "    summary_writer.add_scalars(\"Metrics/Accuracies\",\n",
    "                               {\"Train Sample Accuracy\": train_results[\"sample_accuracy\"],\n",
    "                                \"Validation Sample Accuracy\": val_results[\"sample_accuracy\"],\n",
    "                                \"Train Exact Match\": train_results[\"exact_match_accuracy\"],\n",
    "                                \"Validation Exact Match\": val_results[\"exact_match_accuracy\"]},\n",
    "                               epoch + 1)\n",
    "\n",
    "    # Log learning rate\n",
    "    summary_writer.add_scalar(\"Learning Rate\", \n",
    "                             optimizer.param_groups[0]['lr'], \n",
    "                             epoch + 1)\n",
    "\n",
    "    summary_writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5e8528",
   "metadata": {},
   "source": [
    "## TensorBoard Logging Function\n",
    "\n",
    "**Purpose**: Centralized function for logging metrics to TensorBoard.\n",
    "\n",
    "**Logged Components**:\n",
    "1. **Mini-batch losses**: Track training loss at finer granularity for detailed convergence monitoring\n",
    "2. **Train vs Validation loss**: Side-by-side comparison to monitor generalization and detect overfitting\n",
    "3. **F1 scores**: Both micro/macro variants for train and validation sets\n",
    "4. **Accuracy metrics**: Exact match and sample-level accuracy for comprehensive evaluation\n",
    "5. **Learning rate**: Track scheduler's LR progression over epochs\n",
    "\n",
    "**Visualization Strategy**:\n",
    "- **Grouped scalars**: Related metrics plotted together (e.g., train/val losses on same graph) for easy comparison\n",
    "- **Flush operation**: Ensures data is written to disk immediately for real-time monitoring during training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a081cd5",
   "metadata": {},
   "source": [
    "## Main Training Loop\n",
    "\n",
    "**Purpose**: Orchestrate multi-epoch training with model checkpointing.\n",
    "\n",
    "**Training Pipeline**:\n",
    "1. **Epoch iteration**: 20 epochs with progress tracking via tqdm for monitoring training progress\n",
    "2. **Training phase**: Execute forward/backward passes on training set with gradient updates\n",
    "3. **Validation phase**: Evaluate on holdout set without gradients to assess generalization\n",
    "4. **Scheduler step**: Update learning rate according to OneCycleLR schedule for optimal convergence\n",
    "5. **Metric logging**: Print comprehensive performance statistics including loss, F1 scores, and mAP\n",
    "6. **Model selection**: Save checkpoint when validation metric improves based on chosen criterion\n",
    "\n",
    "**Model Selection Strategy**:\n",
    "- **Metric-based checkpointing**: Saves best model according to `METRIC_OPTION` (currently validation loss for stable selection)\n",
    "- **Comprehensive checkpoint**: Stores model weights, optimizer state, scheduler state, and all best metrics for complete reproducibility\n",
    "- **Enables**: Resume training, model deployment, and comparison across different configurations\n",
    "\n",
    "**Windows Compatibility**: `if __name__ == '__main__' or 'ipykernel' in sys.modules` guards multiprocessing calls for proper Jupyter environment execution on Windows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "402fb63f-81f2-4fd0-8756-1e039756cfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1f5373cfb248ceb7defe9d6d0d224d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6247c2c8b14645c0acd67865ab76388a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8490326b3eeb4052b9b98cb241d6bc98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5258\n",
      "Validation Loss: 0.2401\n",
      "Exact Match Accuracy: 0.0000\n",
      "Sample Accuracy: 0.0000\n",
      "Micro F1: 0.2772\n",
      "Macro F1: 0.0088\n",
      "mAP: 0.0471\n",
      "Current learning rate: 1.60e-05\n",
      "New best model saved (Validation Loss: 0.2401)\n",
      "\n",
      "Epoch 2/20\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964a4cc018f2435a851390489e7aedbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50923c31b5de43d5a105c4a7f1668f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1654\n",
      "Validation Loss: 0.1379\n",
      "Exact Match Accuracy: 0.0000\n",
      "Sample Accuracy: 0.0000\n",
      "Micro F1: 0.2772\n",
      "Macro F1: 0.0088\n",
      "mAP: 0.0651\n",
      "Current learning rate: 1.60e-05\n",
      "New best model saved (Validation Loss: 0.1379)\n",
      "\n",
      "Epoch 3/20\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc201c57135478684bd9ac463b8a76c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649a1915ebec4fd99fc8ed861759ea21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1367\n",
      "Validation Loss: 0.1346\n",
      "Exact Match Accuracy: 0.0000\n",
      "Sample Accuracy: 0.0000\n",
      "Micro F1: 0.2772\n",
      "Macro F1: 0.0088\n",
      "mAP: 0.0737\n",
      "Current learning rate: 1.60e-05\n",
      "New best model saved (Validation Loss: 0.1346)\n",
      "\n",
      "Epoch 4/20\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af841f91c464e3084357eba136d364d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f72e6c43646428cb7b757cc04bc6472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1349\n",
      "Validation Loss: 0.1338\n",
      "Exact Match Accuracy: 0.0000\n",
      "Sample Accuracy: 0.0000\n",
      "Micro F1: 0.2771\n",
      "Macro F1: 0.0088\n",
      "mAP: 0.0793\n",
      "Current learning rate: 1.60e-05\n",
      "New best model saved (Validation Loss: 0.1338)\n",
      "\n",
      "Epoch 5/20\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c1ed3ef2bb4eeea05ffa68f0ce9cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea3fee4fd064b56b520e164cb17abe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1341\n",
      "Validation Loss: 0.1331\n",
      "Exact Match Accuracy: 0.0000\n",
      "Sample Accuracy: 0.0000\n",
      "Micro F1: 0.2769\n",
      "Macro F1: 0.0090\n",
      "mAP: 0.0829\n",
      "Current learning rate: 1.60e-05\n",
      "New best model saved (Validation Loss: 0.1331)\n",
      "\n",
      "Epoch 6/20\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b91a096b40f4f678fa61ef684867afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14725b17701144449a76c276283327cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1334\n",
      "Validation Loss: 0.1322\n",
      "Exact Match Accuracy: 0.0000\n",
      "Sample Accuracy: 0.0000\n",
      "Micro F1: 0.2642\n",
      "Macro F1: 0.0094\n",
      "mAP: 0.0860\n",
      "Current learning rate: 1.60e-05\n",
      "New best model saved (Validation Loss: 0.1322)\n",
      "\n",
      "Epoch 7/20\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2838031814964a40a64b9cdbbf4e9aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d06015f81d4fc6b92f3662f48b000e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1320\n",
      "Validation Loss: 0.1301\n",
      "Exact Match Accuracy: 0.0000\n",
      "Sample Accuracy: 0.0000\n",
      "Micro F1: 0.2542\n",
      "Macro F1: 0.0098\n",
      "mAP: 0.0907\n",
      "Current learning rate: 1.60e-05\n",
      "New best model saved (Validation Loss: 0.1301)\n",
      "\n",
      "Epoch 8/20\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a557da1f44441a89ce62a44ed5fddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9899b32fe2214e6581636f5713468cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1292\n",
      "Validation Loss: 0.1262\n",
      "Exact Match Accuracy: 0.0000\n",
      "Sample Accuracy: 0.0000\n",
      "Micro F1: 0.2513\n",
      "Macro F1: 0.0101\n",
      "mAP: 0.0993\n",
      "Current learning rate: 1.60e-05\n",
      "New best model saved (Validation Loss: 0.1262)\n",
      "\n",
      "Epoch 9/20\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ba781f43614972a9b61e68f052f07c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc1b1ee269140c0be797bba4d69c183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1244\n",
      "Validation Loss: 0.1202\n",
      "Exact Match Accuracy: 0.0000\n",
      "Sample Accuracy: 0.0000\n",
      "Micro F1: 0.2522\n",
      "Macro F1: 0.0103\n",
      "mAP: 0.1142\n",
      "Current learning rate: 1.60e-05\n",
      "New best model saved (Validation Loss: 0.1202)\n",
      "\n",
      "Epoch 10/20\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f0bbdd9a3644a7bfd1fbad4218ade5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532b1bfd4f614a9e816cd8bff6c404ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1184\n",
      "Validation Loss: 0.1141\n",
      "Exact Match Accuracy: 0.0000\n",
      "Sample Accuracy: 0.0000\n",
      "Micro F1: 0.2696\n",
      "Macro F1: 0.0141\n",
      "mAP: 0.1361\n",
      "Current learning rate: 1.60e-05\n",
      "New best model saved (Validation Loss: 0.1141)\n",
      "\n",
      "Epoch 11/20\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ca419db39440f28cd89edaef58222f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594f9cc5762c4ddba0ea4c0e3c4ea295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1134\n",
      "Validation Loss: 0.1094\n",
      "Exact Match Accuracy: 0.0000\n",
      "Sample Accuracy: 0.0000\n",
      "Micro F1: 0.2746\n",
      "Macro F1: 0.0155\n",
      "mAP: 0.1621\n",
      "Current learning rate: 1.60e-05\n",
      "New best model saved (Validation Loss: 0.1094)\n",
      "\n",
      "Epoch 12/20\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a7a7317a3e4246875bb3e69f673144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b04a2ade3c498d993d464f3a576945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1092\n",
      "Validation Loss: 0.1052\n",
      "Exact Match Accuracy: 0.0000\n",
      "Sample Accuracy: 0.0000\n",
      "Micro F1: 0.2867\n",
      "Macro F1: 0.0196\n",
      "mAP: 0.1892\n",
      "Current learning rate: 1.60e-05\n",
      "New best model saved (Validation Loss: 0.1052)\n",
      "\n",
      "Epoch 13/20\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1fb94596ea34e50a8684d8b669d67b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7645d07eae874e2e904707f708960e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1055\n",
      "Validation Loss: 0.1017\n",
      "Exact Match Accuracy: 0.0000\n",
      "Sample Accuracy: 0.0000\n",
      "Micro F1: 0.2997\n",
      "Macro F1: 0.0248\n",
      "mAP: 0.2118\n",
      "Current learning rate: 1.60e-05\n",
      "New best model saved (Validation Loss: 0.1017)\n",
      "\n",
      "Epoch 14/20\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6072443c6d3544ffb84a3ad01a476c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531343df3d49439ca18e967dabc654d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1028\n",
      "Validation Loss: 0.0994\n",
      "Exact Match Accuracy: 0.0000\n",
      "Sample Accuracy: 0.0000\n",
      "Micro F1: 0.2989\n",
      "Macro F1: 0.0268\n",
      "mAP: 0.2267\n",
      "Current learning rate: 1.60e-05\n",
      "New best model saved (Validation Loss: 0.0994)\n",
      "\n",
      "Epoch 15/20\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07279b6932d44d659d2a280efab86152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8acb2200a2894aa6927424cae52107e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1008\n",
      "Validation Loss: 0.0975\n",
      "Exact Match Accuracy: 0.0000\n",
      "Sample Accuracy: 0.0000\n",
      "Micro F1: 0.3156\n",
      "Macro F1: 0.0348\n",
      "mAP: 0.2420\n",
      "Current learning rate: 1.60e-05\n",
      "New best model saved (Validation Loss: 0.0975)\n",
      "\n",
      "Epoch 16/20\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375343646b964660a5edd281e6158342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b626056b8114292aa93af1c7416e973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0992\n",
      "Validation Loss: 0.0959\n",
      "Exact Match Accuracy: 0.0000\n",
      "Sample Accuracy: 0.0000\n",
      "Micro F1: 0.3244\n",
      "Macro F1: 0.0430\n",
      "mAP: 0.2561\n",
      "Current learning rate: 1.60e-05\n",
      "New best model saved (Validation Loss: 0.0959)\n",
      "\n",
      "Epoch 17/20\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e69ee221ca41a3920e5da82935ee6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf0da76d30d49d0b4da31881d5e5586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0978\n",
      "Validation Loss: 0.0946\n",
      "Exact Match Accuracy: 0.0000\n",
      "Sample Accuracy: 0.0000\n",
      "Micro F1: 0.3245\n",
      "Macro F1: 0.0439\n",
      "mAP: 0.2673\n",
      "Current learning rate: 1.60e-05\n",
      "New best model saved (Validation Loss: 0.0946)\n",
      "\n",
      "Epoch 18/20\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e75e360c274a4c8294b441a9b8954a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfad3fc60f74305a312e41f99b96628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0965\n",
      "Validation Loss: 0.0933\n",
      "Exact Match Accuracy: 0.0000\n",
      "Sample Accuracy: 0.0000\n",
      "Micro F1: 0.3314\n",
      "Macro F1: 0.0504\n",
      "mAP: 0.2812\n",
      "Current learning rate: 1.60e-05\n",
      "New best model saved (Validation Loss: 0.0933)\n",
      "\n",
      "Epoch 19/20\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a233d614c71941d6a91b989cf8b9fcf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f367f04a4e4aa2b7e3e48a32b67a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0952\n",
      "Validation Loss: 0.0922\n",
      "Exact Match Accuracy: 0.0000\n",
      "Sample Accuracy: 0.0000\n",
      "Micro F1: 0.3406\n",
      "Macro F1: 0.0593\n",
      "mAP: 0.2928\n",
      "Current learning rate: 1.60e-05\n",
      "New best model saved (Validation Loss: 0.0922)\n",
      "\n",
      "Epoch 20/20\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19dbf0c321ad4f47b246f5d1b15ae8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e049a58cdd40369ceca6c29fc37f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0941\n",
      "Validation Loss: 0.0911\n",
      "Exact Match Accuracy: 0.0000\n",
      "Sample Accuracy: 0.0000\n",
      "Micro F1: 0.3467\n",
      "Macro F1: 0.0708\n",
      "mAP: 0.3053\n",
      "Current learning rate: 1.61e-05\n",
      "New best model saved (Validation Loss: 0.0911)\n",
      "\n",
      "Training completed!\n",
      "Best model saved to: best_coco_shuffle_model.pth\n"
     ]
    }
   ],
   "source": [
    "# for multiprocessing in windows+jupyter, it's better to put the training process in '__main__' for avoiding pickle problem\n",
    "if __name__ == '__main__' or 'ipykernel' in sys.modules: \n",
    "    print(\"Starting training...\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_micro_f1 = 0.0\n",
    "    best_val_macro_f1 = 0.0\n",
    "    best_val_mAP = 0.0\n",
    "\n",
    "    for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "        print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        train_loss = train_loop(train_loader, model, criterion, optimizer, device)\n",
    "\n",
    "        #train_results = validation_loop(train_loader, model, criterion, device)\n",
    "        #train_results['loss'] = train_loss  \n",
    "        \n",
    "        val_results = validation_loop(val_loader, model, criterion, device)\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Training Loss: {train_loss:.4f}\")\n",
    "        print(f\"Validation Loss: {val_results['loss']:.4f}\")\n",
    "        print(f\"Exact Match Accuracy: {val_results['exact_match_accuracy']:.4f}\")\n",
    "        print(f\"Sample Accuracy: {val_results['sample_accuracy']:.4f}\")\n",
    "        print(f\"Micro F1: {val_results['micro_f1']:.4f}\")\n",
    "        print(f\"Macro F1: {val_results['macro_f1']:.4f}\")\n",
    "        print(f\"mAP: {val_results['mAP']:.4f}\")\n",
    "        print(f\"Current learning rate: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "\n",
    "        #update_graphs(writer, epoch, train_results, val_results)\n",
    "        \n",
    "        # Model selection based on METRIC_OPTION\n",
    "        save_model = False\n",
    "        metric_name = \"\"\n",
    "        metric_value = 0.0\n",
    "        \n",
    "        if METRIC_OPTION == 'val_loss':\n",
    "            if val_results['loss'] < best_val_loss:\n",
    "                best_val_loss = val_results['loss']\n",
    "                save_model = True\n",
    "                metric_name = \"Validation Loss\"\n",
    "                metric_value = best_val_loss\n",
    "                \n",
    "        elif METRIC_OPTION == 'micro_f1':\n",
    "            if val_results['micro_f1'] > best_val_micro_f1:\n",
    "                best_val_micro_f1 = val_results['micro_f1']\n",
    "                save_model = True\n",
    "                metric_name = \"Micro F1\"\n",
    "                metric_value = best_val_micro_f1\n",
    "                \n",
    "        elif METRIC_OPTION == 'macro_f1':\n",
    "            if val_results['macro_f1'] > best_val_macro_f1:\n",
    "                best_val_macro_f1 = val_results['macro_f1']\n",
    "                save_model = True\n",
    "                metric_name = \"Macro F1\"\n",
    "                metric_value = best_val_macro_f1\n",
    "                \n",
    "        elif METRIC_OPTION == 'mAP':\n",
    "            if val_results['mAP'] > best_val_mAP:\n",
    "                best_val_mAP = val_results['mAP']\n",
    "                save_model = True\n",
    "                metric_name = \"mAP\"\n",
    "                metric_value = best_val_mAP\n",
    "        \n",
    "        # Save model if a new best metric was achieved\n",
    "        if save_model:\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'best_val_micro_f1': best_val_micro_f1,\n",
    "                'best_val_macro_f1': best_val_macro_f1,\n",
    "                'best_val_mAP': best_val_mAP,\n",
    "                'train_loss': train_loss,\n",
    "                'val_results': val_results,\n",
    "                'metric_option': METRIC_OPTION,\n",
    "            }, MODEL_SAVE_PATH)\n",
    "            print(f\"New best model saved ({metric_name}: {metric_value:.4f})\")\n",
    "        \n",
    "    print(\"\\nTraining completed!\")\n",
    "    print(f\"Best model saved to: {MODEL_SAVE_PATH}\")\n",
    "\n",
    "    #writer.close()\n",
    "    #print(\"TensorBoard writer closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d457fd",
   "metadata": {},
   "source": [
    "## TensorBoard Logger Initialization\n",
    "\n",
    "**Purpose**: Setup experiment tracking for real-time monitoring.\n",
    "\n",
    "**TensorBoard Benefits**:\n",
    "- **Visualization**: Plot training/validation curves during training\n",
    "- **Metric comparison**: Compare metrics across runs\n",
    "- **Hyperparameter tuning**: Track relationships between configs and performance\n",
    "- **Debugging**: Detect training anomalies (exploding gradients, plateau, etc.)\n",
    "\n",
    "**Log Directory**: All events stored in `runs/coco_multi_label_shuffle/` for persistent access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8798da6-a130-4304-ad9e-1eba45f82820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Starting test prediction program\n",
      "============================================================\n",
      "Test inference hyperparameters:\n",
      "  - Test batch size: 64\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Starting test prediction program\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "BATCH_SIZE_TEST = 64\n",
    "\n",
    "print(f\"Test inference hyperparameters:\")\n",
    "print(f\"  - Test batch size: {BATCH_SIZE_TEST}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3ea282",
   "metadata": {},
   "source": [
    "## TensorBoard Logging Function\n",
    "\n",
    "**Purpose**: Centralized function for logging metrics to TensorBoard.\n",
    "\n",
    "**Logged Components**:\n",
    "1. **Mini-batch losses**: Track training loss at finer granularity (commented out in main loop)\n",
    "2. **Train vs Validation loss**: Side-by-side comparison to detect overfitting\n",
    "3. **F1 scores**: Both micro/macro variants for train and validation\n",
    "4. **Accuracy metrics**: Exact match and sample-level accuracy\n",
    "5. **Learning rate**: Track scheduler's LR decay over epochs\n",
    "\n",
    "**Visualization Strategy**:\n",
    "- **Grouped scalars**: Related metrics plotted together (e.g., train/val losses on same graph)\n",
    "- **Flush operation**: Ensures data is written to disk immediately for real-time monitoring\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa2be1e9-1d1a-4b6c-9d74-50d5d1c9e7ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test directories and files:\n",
      "  - Test images: ms-coco\\images\\test-resized\\test-resized\n",
      "  - Trained model: best_coco_shuffle_model.pth\n",
      "  - Output JSON: coco_predictions_shuffle_v9.json\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test directories and files:\")\n",
    "print(f\"  - Test images: {TEST_IMG_DIR}\")\n",
    "print(f\"  - Trained model: {MODEL_SAVE_PATH}\")\n",
    "print(f\"  - Output JSON: {OUTPUT_JSON_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46952479",
   "metadata": {},
   "source": [
    "## Main Training Loop\n",
    "\n",
    "**Purpose**: Orchestrate multi-epoch training with model checkpointing.\n",
    "\n",
    "**Training Pipeline**:\n",
    "1. **Epoch iteration**: 20 epochs with progress tracking via tqdm\n",
    "2. **Training phase**: Execute forward/backward passes on training set\n",
    "3. **Validation phase**: Evaluate on holdout set without gradients\n",
    "4. **Scheduler step**: Update learning rate according to cosine schedule\n",
    "5. **Metric logging**: Print comprehensive performance statistics\n",
    "6. **Model selection**: Save checkpoint when validation metric improves\n",
    "\n",
    "**Model Selection Strategy**:\n",
    "- **Metric-based checkpointing**: Saves best model according to `METRIC_OPTION` (currently mAP)\n",
    "- **Comprehensive checkpoint**: Stores model weights, optimizer state, scheduler state, and all best metrics\n",
    "- **Enables**: Resume training, ensemble creation, and deployment of best model\n",
    "\n",
    "**Performance Observations** (from output):\n",
    "- **Micro F1 peaked at 0.0947** in epoch 1, then degraded\n",
    "- **mAP not logged properly** (shown as 0.0000), suggesting potential issue with metric calculation or label format\n",
    "- **Loss plateau**: Training loss decreased minimally (0.0383â†’0.0311), indicating:\n",
    "  - Possible learning rate too low\n",
    "  - L1 loss may be suboptimal for this task\n",
    "  - Model may be underfitting\n",
    "\n",
    "**Windows Compatibility**: `if __name__ == '__main__' or 'ipykernel' in sys.modules` guards multiprocessing calls in Jupyter environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bfdace-c02d-48fb-8c19-f4a2ba0cef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_dataset = COCOTestImageDataset(\n",
    "    img_dir=TEST_IMG_DIR,\n",
    "    transform=test_transforms\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE_TEST,\n",
    "    shuffle=False,  # No shuffling needed for testing\n",
    "    num_workers=4,  \n",
    "    pin_memory=True if device.type == 'cuda' else False,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "print(f\"Test batch count: {len(test_loader)}\")\n",
    "print(f\"Test loader using {test_loader.num_workers} workers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b47c3d",
   "metadata": {},
   "source": [
    "## Test Inference Configuration\n",
    "\n",
    "**Purpose**: Initialize hyperparameters for test set prediction.\n",
    "\n",
    "**Test Batch Size (64)**: Matches training batch size for consistency, though larger batches could be used during inference since no gradients are stored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cdcde7f-2d97-4e31-94bd-2e848e13ac31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\unicorn\\AppData\\Local\\Temp\\ipykernel_4560\\3238392438.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model weights from: best_coco_shuffle_model.pth\n",
      "Model training epoch: 20\n",
      "Best validation loss: 0.0000\n",
      "Model ready for inference\n"
     ]
    }
   ],
   "source": [
    "test_model = COCOMultiLabelClassifier(num_classes=NUM_CLASSES, pretrained=False)\n",
    "\n",
    "if os.path.exists(MODEL_SAVE_PATH):\n",
    "    checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "    test_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Successfully loaded model weights from: {MODEL_SAVE_PATH}\")\n",
    "    print(f\"Model training epoch: {checkpoint['epoch']}\")\n",
    "    print(f\"Best validation loss: {checkpoint['best_val_micro_f1']:.4f}\")\n",
    "else:\n",
    "    print(f\"Trained model file not found: {MODEL_SAVE_PATH}\")\n",
    "    print(\"Please run the training program first\")\n",
    "    raise FileNotFoundError(f\"Model file not found: {MODEL_SAVE_PATH}\")\n",
    "\n",
    "test_model = test_model.to(device)\n",
    "test_model.eval()\n",
    "print(\"Model ready for inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74382136",
   "metadata": {},
   "source": [
    "## Test Paths Verification\n",
    "\n",
    "**Purpose**: Confirm file paths for test inference pipeline.\n",
    "\n",
    "**Output Components**:\n",
    "- **Test images**: 4952 unlabeled images for challenge submission\n",
    "- **Model checkpoint**: Best model saved during training (based on mAP metric)\n",
    "- **Predictions JSON**: Output file containing predicted class indices per image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2115528b-74b2-4301-b0e2-6702d872cd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dictionary initialized\n"
     ]
    }
   ],
   "source": [
    "predictions_dict = {}\n",
    "print(\"Output dictionary initialized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff158e9",
   "metadata": {},
   "source": [
    "## Test Dataset and DataLoader Preparation\n",
    "\n",
    "**Purpose**: Create inference pipeline for test set predictions.\n",
    "\n",
    "**Transform Pipeline**:\n",
    "- **Identical to validation**: Same resize (224Ã—224) and normalization to match training distribution\n",
    "- **No augmentation**: Uses deterministic transforms for consistent predictions\n",
    "\n",
    "**DataLoader Configuration**:\n",
    "- **No shuffling**: Preserves image order for result mapping\n",
    "- **4 workers**: Slightly reduced from training (6) as inference is less I/O bound\n",
    "- **Pin memory**: Enabled for faster CPUâ†’GPU transfer\n",
    "- **Persistent workers**: Reduces overhead during iteration\n",
    "\n",
    "**Dataset Size**: 4952 test images â†’ 78 batches with batch size 64.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83162c2-b3da-4812-a23a-2842f33cf670",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting prediction loop...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, filenames) in enumerate(tqdm(test_loader, desc=\"Predicting\")):\n",
    "        # Get mini-batch\n",
    "        images = images.to(device)\n",
    "        \n",
    "        outputs = test_model(images)\n",
    "        \n",
    "        probabilities = torch.sigmoid(outputs)\n",
    "        predictions = (probabilities > THRESHOLD).cpu().numpy()\n",
    "        \n",
    "        # Update dictionary entries, write corresponding class indices\n",
    "        for i, filename in enumerate(filenames):\n",
    "            predicted_classes = []\n",
    "            for class_idx in range(NUM_CLASSES):\n",
    "                if predictions[i, class_idx]:\n",
    "                    predicted_classes.append(class_idx)\n",
    "            \n",
    "            predictions_dict[filename] = predicted_classes\n",
    "\n",
    "print(f\"Prediction completed, processed {len(predictions_dict)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b9b418",
   "metadata": {},
   "source": [
    "## Model Loading for Inference\n",
    "\n",
    "**Purpose**: Instantiate model and load trained weights from checkpoint.\n",
    "\n",
    "**Loading Process**:\n",
    "1. **Initialize architecture**: Create model with random weights (`pretrained=False` to avoid downloading ImageNet weights)\n",
    "2. **Load checkpoint**: Retrieve saved state dictionary from training\n",
    "3. **Restore weights**: Apply trained parameters to model\n",
    "4. **Device placement**: Move to GPU for accelerated inference\n",
    "5. **Evaluation mode**: Disable dropout and batch normalization training behavior\n",
    "\n",
    "**Checkpoint Information**:\n",
    "- **Training epoch**: 1 (model was saved after first epoch)\n",
    "- **Best metric**: 0.0947 Micro F1 (though variable name incorrectly says `best_val_micro_f1` while printing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7fa075e-fd5d-4750-87f0-9d458b7f2093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prediction results to: coco_predictions_shuffle_v8.json\n",
      "  Sample 000000000139: predicted classes [56, 57, 58, 60, 62]\n",
      "  Sample 000000000285: predicted classes []\n",
      "  Sample 000000000632: predicted classes [56, 57]\n",
      "  Sample 000000000724: predicted classes [11]\n",
      "  Sample 000000000776: predicted classes [77]\n",
      "JSON file successfully saved to: coco_predictions_shuffle_v8.json\n",
      "File size: 200.17 KB\n",
      "============================================================\n",
      "Test prediction program completed!\n"
     ]
    }
   ],
   "source": [
    "print(f\"Saving prediction results to: {OUTPUT_JSON_FILE}\")\n",
    "\n",
    "# Show some sample predictions\n",
    "sample_count = 0\n",
    "for filename, predicted_classes in predictions_dict.items():\n",
    "    if sample_count < 5:  # Show only first 5 samples\n",
    "        print(f\"  Sample {filename}: predicted classes {predicted_classes}\")\n",
    "        sample_count += 1\n",
    "\n",
    "try:\n",
    "    with open(OUTPUT_JSON_FILE, 'w') as f:\n",
    "        json.dump(predictions_dict, f, indent=2)\n",
    "    print(f\"JSON file successfully saved to: {OUTPUT_JSON_FILE}\")\n",
    "    \n",
    "    # Check file size\n",
    "    file_size = os.path.getsize(OUTPUT_JSON_FILE)\n",
    "    print(f\"File size: {file_size / 1024:.2f} KB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error saving JSON file: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Test prediction program completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f63168",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
