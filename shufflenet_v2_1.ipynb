{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8a4a768",
   "metadata": {},
   "source": [
    "## Library Imports and Environment Setup\n",
    "\n",
    "**Design Rationale**: Separating dataset classes into a standalone Python module resolves Windows-specific pickling issues when using `num_workers > 0` in DataLoader, enabling parallel data loading for faster training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9094f777-f1c1-4224-b248-3a044861fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements for python, torch and companion libraries and your own modules\n",
    "import os\n",
    "import sys\n",
    "#nb_dir = os.path.split(os.getcwd())[0]\n",
    "#if nb_dir not in sys.path:\n",
    "    #sys.path.append(nb_dir)\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "\n",
    "#from lion_pytorch import Lion\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import shufflenet_v2_x1_0, ShuffleNet_V2_X1_0_Weights\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Import dataset classes from dataset.py for Windows multiprocessing support\n",
    "from dataset import COCOTrainImageDataset, COCOTestImageDataset, ValidationDataset\n",
    "\n",
    "print(\"All libraries imported successfully\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6177cf30",
   "metadata": {},
   "source": [
    "## Reproducibility Configuration\n",
    "\n",
    "**Technical Details**:\n",
    "- **Fixed random seeds (42)**: Ensures identical weight initialization and data shuffling across experiments for reproducible results\n",
    "- **cuDNN settings**:\n",
    "  - `deterministic=False`: Prioritizes computational performance, as cuDNN can select fastest algorithms\n",
    "  - `benchmark=True`: Enables cuDNN autotuner to benchmark and select optimal convolution algorithms for the fixed input size，for speedingup\n",
    "\n",
    "**Rationale**: The seeded initialization ensures consistent starting conditions for fair model comparison, while cuDNN optimization maximizes training efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7286f114-09ea-4ea1-88d3-362671cb0cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = False  \n",
    "    torch.backends.cudnn.benchmark = True  \n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dd44f2",
   "metadata": {},
   "source": [
    "## Hyperparameter Configuration\n",
    "\n",
    "**Key Hyperparameters**:\n",
    "- **Batch size (128)**: Larger batch size enables more stable gradient estimates and better GPU utilization, allowing for slightly higher learning rates through linear scaling rule\n",
    "- **Learning rate (3e-4)**: Scaled from base 3e-4 for efficient convergence within 20 epochs, suitable for fine-tuning the lightweight ShuffleNet architecture on COCO\n",
    "- **Weight decay (1e-5)**: Moderate L2 regularization strength provides effective generalization on 65K training samples without over-constraining model capacity\n",
    "\n",
    "**Model Selection Metric**:\n",
    "- **Validation Loss**: Direct optimization target that provides stable and reliable checkpointing, ensuring the saved model represents the best generalization performance, slightly better in MS COCO dataset than micro f1, macro f1 and mAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e4257-d696-4a4b-ba57-dfb209dba058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables defining training hyper-parameters among other things \n",
    "BATCH_SIZE = 128  \n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 3e-4  \n",
    "WEIGHT_DECAY = 1e-5\n",
    "NUM_CLASSES = 80\n",
    "VALIDATION_SPLIT = 0.1\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "\n",
    "# Options: 'val_loss', 'micro_f1', 'macro_f1', 'mAP'\n",
    "METRIC_OPTION = 'val_loss'  \n",
    "\n",
    "print(\"Global variables and hyperparameters defined:\")\n",
    "print(f\"  - Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  - Number of epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  - Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  - Validation split: {VALIDATION_SPLIT}\")\n",
    "print(f\"  - Threshold: {THRESHOLD}\")\n",
    "print(f\"  - Model selection metric: {METRIC_OPTION}\")\n",
    "\n",
    "# device initialization\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae905931",
   "metadata": {},
   "source": [
    "## Dataset Class Import Confirmation\n",
    "\n",
    "**Windows-Specific Requirement**: PyTorch's DataLoader with multiprocessing on Windows requires Dataset classes to be importable from a separate `.py` file (not notebook-defined) to enable proper serialization via pickle protocol. This message confirms the architecture follows Windows best practices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b31cd1d-5acf-4cd8-8dde-49409a28d52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data directories initialization\n",
    "DATA_DIR = \"ms-coco\"\n",
    "TRAIN_IMG_DIR = os.path.join(DATA_DIR, \"images\", \"train-resized\", \"train-resized\")\n",
    "TEST_IMG_DIR = os.path.join(DATA_DIR, \"images\", \"test-resized\", \"test-resized\")\n",
    "TRAIN_LABELS_DIR = os.path.join(DATA_DIR, \"labels\", \"train\")\n",
    "MODEL_SAVE_PATH = \"best_coco_shuffle_model.pth\"\n",
    "OUTPUT_JSON_FILE = \"coco_predictions_shuffle_v9.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c5467-88d4-4ab5-b910-9a8d9650fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class definitions\n",
    "classes = (\"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\", \n",
    "           \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\",\n",
    "           \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\",       \n",
    "           \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
    "           \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n",
    "           \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\", \n",
    "           \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \n",
    "           \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \n",
    "           \"hair drier\", \"toothbrush\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377a65a4-12c8-4855-bc63-32c78e291553",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data directories and class names defined:\")\n",
    "print(f\"  - Training images: {TRAIN_IMG_DIR}\")\n",
    "print(f\"  - Test images: {TEST_IMG_DIR}\")\n",
    "print(f\"  - Training labels: {TRAIN_LABELS_DIR}\")\n",
    "print(f\"  - Dataset contains {NUM_CLASSES} classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124122de",
   "metadata": {},
   "source": [
    "## Data Augmentation and Dataset Initialization\n",
    "\n",
    "**Training Augmentations**:\n",
    "- **Resize to 224×224**: Matches ShuffleNet V2 input requirements (standard ImageNet dimensions)\n",
    "- **BILINEAR interpolation**: Smooth resampling preserving edge details better than nearest-neighbor\n",
    "- **RandomHorizontalFlip (p=0.5)**: Introduces horizontal symmetry as data augmentation, effective for object-centric datasets like COCO where orientation variance exists\n",
    "- **ImageNet normalization**: Uses standard mean=[0.485, 0.456, 0.406] and std=[0.229, 0.224, 0.225] to match pre-training statistics, crucial for transfer learning\n",
    "\n",
    "**Validation Transformations**:\n",
    "- **No augmentation**: Only resize and normalize to evaluate model on clean data\n",
    "- Ensures unbiased performance estimation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d4de6-7658-42e9-bdc3-6d27c95aadc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiation of transforms, datasets and data loaders\n",
    "# TIP : use torch.utils.data.random_split to split the training set into train and validation subsets\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.BILINEAR),   \n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create full training dataset\n",
    "print(\"Loading dataset...\")\n",
    "full_train_dataset = COCOTrainImageDataset(\n",
    "    img_dir=TRAIN_IMG_DIR,\n",
    "    annotations_dir=TRAIN_LABELS_DIR,\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "print(f\"Full training dataset size: {len(full_train_dataset)}\")\n",
    "\n",
    "train_size = int((1 - VALIDATION_SPLIT) * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_train_dataset, \n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c0b5c2-fe6a-4ca1-9973-bbc1d18351cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_transformed = ValidationDataset(val_dataset, val_transforms)\n",
    "\n",
    "# Create data loaders with Windows-compatible multiprocessing settings\n",
    "# For Windows, we can now use num_workers > 0 since dataset classes are in separate .py file\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=6,  \n",
    "    pin_memory=True,  \n",
    "    drop_last=True,\n",
    "    persistent_workers=True  # Keep workers alive between epochs\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset_transformed, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=6,  \n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "print(\"Data loaders created successfully with Windows multiprocessing support\")\n",
    "print(f\"  - Training loader: {len(train_loader)} batches, {train_loader.num_workers} workers\")\n",
    "print(f\"  - Validation loader: {len(val_loader)} batches, {val_loader.num_workers} workers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d622796",
   "metadata": {},
   "source": [
    "## Model Architecture Definition\n",
    "\n",
    "**Backbone Choice - ShuffleNet V2 x1.0**:\n",
    "- **Efficiency-oriented**: Designed for mobile/edge devices with only ~2M parameters, enabling fast training and inference\n",
    "- **Channel shuffle mechanism**: Enables efficient cross-group information exchange without expensive 1×1 convolutions\n",
    "- **Pre-trained on ImageNet**: Provides strong initial feature extractors for transfer learning\n",
    "- **COCO training experience**: ShuffleNet has been successfully trained on COCO dataset in prior work, demonstrating its effectiveness for multi-label object classification tasks\n",
    "- **Compact model size**: The relatively small parameter count (~1.8M) allows for more transparent observation of how each fine-tuning operation affects model performance, making it ideal for experimental analysis and hyperparameter tuning\n",
    "\n",
    "**Classification Head Design**:\n",
    "- **Dropout layers (0.3, 0.2)**: Stochastic regularization with graduated dropout rates - higher in first layer where features are more task-specific, lower before final classification\n",
    "- **Intermediate 512-dim layer**: Provides sufficient capacity for learning complex multi-label patterns while maintaining parameter efficiency\n",
    "- **ReLU activation**: Standard non-linearity for intermediate representations, enabling effective gradient flow\n",
    "- **Output dimension = 80**: One logit per COCO class for independent multi-label prediction\n",
    "\n",
    "**Multi-Label Formulation**: Unlike single-label classification, no softmax is applied - instead, sigmoid activation (applied later) treats each class independently, enabling multiple simultaneous predictions per image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b8d27-dafe-4770-8c34-603330f9df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCOMultiLabelClassifier(nn.Module):\n",
    "    def __init__(self, num_classes: int = 80, pretrained: bool = True):\n",
    "        super(COCOMultiLabelClassifier, self).__init__()\n",
    "        \n",
    "        # Use pre-trained ShuffleNet V2 x1.0 as backbone\n",
    "        if pretrained:\n",
    "            self.backbone = shufflenet_v2_x1_0(weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1)\n",
    "        else:\n",
    "            self.backbone = shufflenet_v2_x1_0(weights=None)\n",
    "        \n",
    "        # ShuffleNet V2 x1.0 has 1024 output features\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        \n",
    "        # Replace classification head with multi-label classification head\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df4cefe",
   "metadata": {},
   "source": [
    "## DataLoader Configuration with Multiprocessing\n",
    "\n",
    "**Optimization Strategies**:\n",
    "- **num_workers=6**: Spawns 6 background processes for asynchronous data loading, reducing GPU idle time\n",
    "- **pin_memory=True**: Allocates tensors in page-locked memory for faster CPU→GPU transfer via DMA\n",
    "- **persistent_workers=True**: Keeps worker processes alive between epochs, avoiding spawn overhead (significant on Windows)\n",
    "- **drop_last=True** (train only): Ensures consistent batch sizes, preventing batch normalization issues with small final batches\n",
    "\n",
    "**Windows Compatibility**: The combination of external dataset module + persistent workers resolves common Windows DataLoader errors while maximizing throughput.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d09d758-7c30-4df4-a2b4-e77c429d372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiation and preparation of network model\n",
    "print(\"Initializing model...\")\n",
    "model = COCOMultiLabelClassifier(num_classes=NUM_CLASSES, pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model loaded to device: {device}\")\n",
    "print(f\"  - Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"  - Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc67e949",
   "metadata": {},
   "source": [
    "## Mean Average Precision (mAP) Metric Implementation\n",
    "\n",
    "**Metric Rationale**:\n",
    "- **mAP superiority over F1**: Evaluates ranking quality across all thresholds, not just a single operating point\n",
    "- **Per-class AP calculation**: Measures precision-recall area for each class independently\n",
    "- **Handles class imbalance**: Averaging per-class APs gives equal weight to rare and common classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e1cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mAP(predictions, labels):\n",
    "    predictions_np = predictions.cpu().numpy()\n",
    "    labels_np = labels.cpu().numpy()\n",
    "    \n",
    "    aps = []\n",
    "    for class_idx in range(labels.shape[1]):\n",
    "        y_true = labels_np[:, class_idx]\n",
    "        y_scores = predictions_np[:, class_idx]\n",
    "        \n",
    "        # Skip classes with no positive samples\n",
    "        if y_true.sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        # Sort by prediction scores (descending)\n",
    "        sorted_indices = np.argsort(-y_scores)\n",
    "        y_true_sorted = y_true[sorted_indices]\n",
    "        \n",
    "        # Calculate precision at each threshold\n",
    "        tp = np.cumsum(y_true_sorted)\n",
    "        fp = np.cumsum(1 - y_true_sorted)\n",
    "        \n",
    "        precision = tp / (tp + fp + 1e-8)\n",
    "        \n",
    "        total_positives = y_true.sum()\n",
    "        recall = tp / total_positives\n",
    "        \n",
    "        precision = np.concatenate([[0], precision, [0]])\n",
    "        recall = np.concatenate([[0], recall, [1]])\n",
    "        \n",
    "        for i in range(len(precision) - 2, -1, -1):\n",
    "            precision[i] = max(precision[i], precision[i + 1])\n",
    "        \n",
    "        ap = np.sum((recall[1:] - recall[:-1]) * precision[1:])\n",
    "        aps.append(ap)\n",
    "    \n",
    "    if len(aps) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    mAP = np.mean(aps)\n",
    "    return float(mAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10d38dc",
   "metadata": {},
   "source": [
    "## F1 Score Metrics (Micro and Macro)\n",
    "\n",
    "**Micro F1**:\n",
    "- **Global aggregation**: Computes precision/recall from aggregated TP/FP/FN across all classes\n",
    "- **Interpretation**: Overall performance weighted by class frequency\n",
    "- **Bias**: Favors common classes in imbalanced datasets\n",
    "\n",
    "**Macro F1**:\n",
    "- **Per-class averaging**: Computes F1 for each class independently, then averages\n",
    "- **Interpretation**: Treats all classes equally regardless of frequency\n",
    "- **Bias**: Better reflects performance on rare classes\n",
    "\n",
    "**Use Case**: Macro F1 is particularly valuable for COCO's long-tailed distribution where rare objects should be weighted equally with common ones \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22549af-61ff-4797-9526-0e8851ba54d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for select the best model\n",
    "def calculate_f1_metrics(predictions, labels, threshold=0.5):\n",
    "\n",
    "    predictions_binary = (predictions > threshold).float()\n",
    "    tp = (predictions_binary * labels).sum()\n",
    "    fp = (predictions_binary * (1 - labels)).sum() \n",
    "    fn = ((1 - predictions_binary) * labels).sum()\n",
    "    \n",
    "    micro_precision = tp / (tp + fp + 1e-8)\n",
    "    micro_recall = tp / (tp + fn + 1e-8)\n",
    "    micro_f1 = 2 * micro_precision * micro_recall / (micro_precision + micro_recall + 1e-8)\n",
    "    \n",
    "    class_f1s = []\n",
    "    for c in range(labels.shape[1]):\n",
    "        tp_c = (predictions_binary[:, c] * labels[:, c]).sum()\n",
    "        fp_c = (predictions_binary[:, c] * (1 - labels[:, c])).sum()\n",
    "        fn_c = ((1 - predictions_binary[:, c]) * labels[:, c]).sum()\n",
    "        \n",
    "        prec_c = tp_c / (tp_c + fp_c + 1e-8)\n",
    "        rec_c = tp_c / (tp_c + fn_c + 1e-8)\n",
    "        f1_c = 2 * prec_c * rec_c / (prec_c + rec_c + 1e-8)\n",
    "        class_f1s.append(f1_c)\n",
    "    \n",
    "    macro_f1 = torch.stack(class_f1s).mean()\n",
    "    return float(micro_f1), float(macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1bf3d5-fb71-4fb7-8610-8167335f49de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(train_loader: DataLoader, net: nn.Module, criterion: nn.Module, \n",
    "               optimizer: optim.Optimizer, device: torch.device) -> float:\n",
    "\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\",position=0, leave=True):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566f95e5-0e55-482d-91a7-2c97680cf0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loop(val_loader: DataLoader, net: nn.Module, criterion: nn.Module, \n",
    "                   device: torch.device) -> Dict[str, float]:\n",
    "\n",
    "    net.eval()\n",
    "    val_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Validating\",position=0, leave=True):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            batch_loss = criterion(outputs, labels)\n",
    "            val_loss += batch_loss.item() * images.size(0)\n",
    "            \n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            \n",
    "            all_predictions.append(probabilities.cpu())  # save the probabilities instead of predictions\n",
    "            all_labels.append(labels.cpu())\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    all_predictions = torch.cat(all_predictions, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "    micro_f1, macro_f1 = calculate_f1_metrics(all_predictions, all_labels)\n",
    "    mAP = calculate_mAP(all_predictions, all_labels)\n",
    "\n",
    "    predictions_binary = (all_predictions > THRESHOLD).float()\n",
    "    exact_match = (all_predictions == all_labels).all(dim=1).float().mean().item()\n",
    "    \n",
    "    sample_accuracy = ((all_predictions == all_labels).float().mean(dim=1)).mean().item()\n",
    "    \n",
    "    return {\n",
    "        'loss': val_loss,\n",
    "        'exact_match_accuracy': exact_match,\n",
    "        'sample_accuracy': sample_accuracy,\n",
    "        'micro_f1': micro_f1,\n",
    "        'macro_f1': macro_f1,\n",
    "        'mAP': mAP,\n",
    "        'predictions': all_predictions,\n",
    "        'labels': all_labels\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d188d0bf",
   "metadata": {},
   "source": [
    "## Loss Function and Optimizer Configuration\n",
    "\n",
    "**Loss Function - BCEWithLogitsLoss**:\n",
    "- **Standard multi-label loss**: Combines sigmoid activation and binary cross-entropy in a numerically stable single operation\n",
    "- **Numerically stable**: Computes log-sum-exp trick internally to prevent overflow/underflow issues\n",
    "- **Multi-label formulation**: Treats each class independently, computing binary cross-entropy for all 80 classes simultaneously\n",
    "- **Probabilistic gradients**: Provides well-calibrated gradients for learning probability distributions, essential for multi-label classification\n",
    "\n",
    "**Optimizer - AdamW**:\n",
    "- **Adaptive learning rates**: Per-parameter learning rates automatically adjust based on first and second moment estimates of gradients\n",
    "- **Weight decay decoupling**: Applies L2 regularization correctly by decoupling it from gradient-based updates, fixing Adam's implementation flaw\n",
    "- **Fast convergence**: Adaptive method enables efficient convergence within 20 epochs on COCO dataset\n",
    "- **Regularization strength**: 1e-5 weight decay provides effective generalization without over-constraining the model\n",
    "\n",
    "**Learning Rate Scheduler - OneCycleLR**:\n",
    "- **Warmup phase**: Initial 30% of training (pct_start=0.15) gradually increases LR, allowing model to adapt to COCO data before aggressive learning\n",
    "- **Peak learning**: Reaches maximum LR (3e-4) for efficient feature learning in middle epochs\n",
    "- **Annealing phase**: Final 70% gradually decreases LR for fine-grained optimization and stable convergence\n",
    "- **Fast training**: OneCycleLR strategy enables strong performance within limited epoch budget (20 epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7416a826-17e6-40ae-9acf-c2e4e8b6ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiation of loss criterion\n",
    "# instantiation of optimizer, registration of network parameters\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "#criterion = nn.L1Loss()\n",
    "\n",
    "print(\"Loss criterion initialized: BCEWithLogitsLoss\")\n",
    "#print(\"Loss criterion initialized: L1Loss\")\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=LEARNING_RATE, \n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "'''\n",
    "optimizer = Lion(\n",
    "    model.parameters(),\n",
    "    lr=1e-5,\n",
    "    weight_decay=1e-2\n",
    ")\n",
    "'''\n",
    "\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=LEARNING_RATE,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    pct_start=0.15\n",
    ")\n",
    "\n",
    "'''\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, \n",
    "    T_max=NUM_EPOCHS, \n",
    "    eta_min=1e-6\n",
    ")\n",
    "'''\n",
    "\n",
    "print(\"Optimizer and scheduler initialized:\")\n",
    "print(f\"  - Optimizer: AdamW\")\n",
    "print(f\"  - Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  - Weight decay: {WEIGHT_DECAY}\")\n",
    "print(f\"  - Scheduler: CosineAnnealingLR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e9639-803b-4050-8f93-d1270256e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"runs/coco_multi_label_shuffle\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "#writer = SummaryWriter(log_dir)\n",
    "\n",
    "#print(f\"Logs will be saved to: {log_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5e8528",
   "metadata": {},
   "source": [
    "## TensorBoard Logging Function\n",
    "\n",
    "**Logged Components**:\n",
    "1. **Mini-batch losses**: Track training loss at finer granularity for detailed convergence monitoring\n",
    "2. **Train vs Validation loss**: Side-by-side comparison to monitor generalization and detect overfitting\n",
    "3. **F1 scores**: Both micro/macro variants for train and validation sets\n",
    "4. **Accuracy metrics**: Exact match and sample-level accuracy for comprehensive evaluation\n",
    "5. **Learning rate**: Track scheduler's LR progression over epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7571322-c64f-4661-b12a-2dc80d37969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_graphs(summary_writer, epoch, train_results, val_results,\n",
    "                  train_class_results=None, val_class_results=None, \n",
    "                  class_names=None, mbatch_group=-1, mbatch_count=0, mbatch_losses=None):\n",
    "    \n",
    "    # Log mini-batch losses if available\n",
    "    if mbatch_group > 0 and mbatch_losses:\n",
    "        for i in range(len(mbatch_losses)):\n",
    "            summary_writer.add_scalar(\"Losses/Train mini-batches\",\n",
    "                                  mbatch_losses[i],\n",
    "                                  epoch * mbatch_count + (i+1)*mbatch_group)\n",
    "\n",
    "    # Log training vs validation losses\n",
    "    summary_writer.add_scalars(\"Losses/Train Loss vs Validation Loss\",\n",
    "                               {\"Train Loss\": train_results[\"loss\"],\n",
    "                                \"Validation Loss\": val_results[\"loss\"]},\n",
    "                               epoch + 1)\n",
    "\n",
    "    # Log F1 scores\n",
    "    summary_writer.add_scalars(\"Metrics/F1 Scores\",\n",
    "                               {\"Train Micro F1\": train_results[\"micro_f1\"],\n",
    "                                \"Validation Micro F1\": val_results[\"micro_f1\"],\n",
    "                                \"Train Macro F1\": train_results[\"macro_f1\"],\n",
    "                                \"Validation Macro F1\": val_results[\"macro_f1\"]},\n",
    "                               epoch + 1)\n",
    "\n",
    "    # Log accuracies\n",
    "    summary_writer.add_scalars(\"Metrics/Accuracies\",\n",
    "                               {\"Train Sample Accuracy\": train_results[\"sample_accuracy\"],\n",
    "                                \"Validation Sample Accuracy\": val_results[\"sample_accuracy\"],\n",
    "                                \"Train Exact Match\": train_results[\"exact_match_accuracy\"],\n",
    "                                \"Validation Exact Match\": val_results[\"exact_match_accuracy\"]},\n",
    "                               epoch + 1)\n",
    "\n",
    "    # Log learning rate\n",
    "    summary_writer.add_scalar(\"Learning Rate\", \n",
    "                             optimizer.param_groups[0]['lr'], \n",
    "                             epoch + 1)\n",
    "\n",
    "    summary_writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a081cd5",
   "metadata": {},
   "source": [
    "## Main Training Loop\n",
    "\n",
    "**Model Selection Strategy**:\n",
    "- **Metric-based checkpointing**: Saves best model according to `METRIC_OPTION` (currently validation loss for stable selection)\n",
    "- **Comprehensive checkpoint**: Stores model weights, optimizer state, scheduler state, and all best metrics for complete reproducibility\n",
    "- **Enables**: Resume training, model deployment, and comparison across different configurations\n",
    "\n",
    "**Windows Compatibility**: `if __name__ == '__main__' or 'ipykernel' in sys.modules` guards multiprocessing calls for proper Jupyter environment execution on Windows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402fb63f-81f2-4fd0-8756-1e039756cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multiprocessing in windows+jupyter, it's better to put the training process in '__main__' for avoiding pickle problem\n",
    "if __name__ == '__main__' or 'ipykernel' in sys.modules: \n",
    "    print(\"Starting training...\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_micro_f1 = 0.0\n",
    "    best_val_macro_f1 = 0.0\n",
    "    best_val_mAP = 0.0\n",
    "\n",
    "    for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "        print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        train_loss = train_loop(train_loader, model, criterion, optimizer, device)\n",
    "\n",
    "        #train_results = validation_loop(train_loader, model, criterion, device)\n",
    "        #train_results['loss'] = train_loss  \n",
    "        \n",
    "        val_results = validation_loop(val_loader, model, criterion, device)\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Training Loss: {train_loss:.4f}\")\n",
    "        print(f\"Validation Loss: {val_results['loss']:.4f}\")\n",
    "        print(f\"Exact Match Accuracy: {val_results['exact_match_accuracy']:.4f}\")\n",
    "        print(f\"Sample Accuracy: {val_results['sample_accuracy']:.4f}\")\n",
    "        print(f\"Micro F1: {val_results['micro_f1']:.4f}\")\n",
    "        print(f\"Macro F1: {val_results['macro_f1']:.4f}\")\n",
    "        print(f\"mAP: {val_results['mAP']:.4f}\")\n",
    "        print(f\"Current learning rate: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "\n",
    "        #update_graphs(writer, epoch, train_results, val_results)\n",
    "        \n",
    "        # Model selection based on METRIC_OPTION\n",
    "        save_model = False\n",
    "        metric_name = \"\"\n",
    "        metric_value = 0.0\n",
    "        \n",
    "        if METRIC_OPTION == 'val_loss':\n",
    "            if val_results['loss'] < best_val_loss:\n",
    "                best_val_loss = val_results['loss']\n",
    "                save_model = True\n",
    "                metric_name = \"Validation Loss\"\n",
    "                metric_value = best_val_loss\n",
    "                \n",
    "        elif METRIC_OPTION == 'micro_f1':\n",
    "            if val_results['micro_f1'] > best_val_micro_f1:\n",
    "                best_val_micro_f1 = val_results['micro_f1']\n",
    "                save_model = True\n",
    "                metric_name = \"Micro F1\"\n",
    "                metric_value = best_val_micro_f1\n",
    "                \n",
    "        elif METRIC_OPTION == 'macro_f1':\n",
    "            if val_results['macro_f1'] > best_val_macro_f1:\n",
    "                best_val_macro_f1 = val_results['macro_f1']\n",
    "                save_model = True\n",
    "                metric_name = \"Macro F1\"\n",
    "                metric_value = best_val_macro_f1\n",
    "                \n",
    "        elif METRIC_OPTION == 'mAP':\n",
    "            if val_results['mAP'] > best_val_mAP:\n",
    "                best_val_mAP = val_results['mAP']\n",
    "                save_model = True\n",
    "                metric_name = \"mAP\"\n",
    "                metric_value = best_val_mAP\n",
    "        \n",
    "        # Save model if a new best metric was achieved\n",
    "        if save_model:\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'best_val_micro_f1': best_val_micro_f1,\n",
    "                'best_val_macro_f1': best_val_macro_f1,\n",
    "                'best_val_mAP': best_val_mAP,\n",
    "                'train_loss': train_loss,\n",
    "                'val_results': val_results,\n",
    "                'metric_option': METRIC_OPTION,\n",
    "            }, MODEL_SAVE_PATH)\n",
    "            print(f\"New best model saved ({metric_name}: {metric_value:.4f})\")\n",
    "        \n",
    "    print(\"\\nTraining completed!\")\n",
    "    print(f\"Best model saved to: {MODEL_SAVE_PATH}\")\n",
    "\n",
    "    #writer.close()\n",
    "    #print(\"TensorBoard writer closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8798da6-a130-4304-ad9e-1eba45f82820",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Starting test prediction program\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "BATCH_SIZE_TEST = 64\n",
    "\n",
    "print(f\"Test inference hyperparameters:\")\n",
    "print(f\"  - Test batch size: {BATCH_SIZE_TEST}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2be1e9-1d1a-4b6c-9d74-50d5d1c9e7ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Test directories and files:\")\n",
    "print(f\"  - Test images: {TEST_IMG_DIR}\")\n",
    "print(f\"  - Trained model: {MODEL_SAVE_PATH}\")\n",
    "print(f\"  - Output JSON: {OUTPUT_JSON_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bfdace-c02d-48fb-8c19-f4a2ba0cef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_dataset = COCOTestImageDataset(\n",
    "    img_dir=TEST_IMG_DIR,\n",
    "    transform=test_transforms\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE_TEST,\n",
    "    shuffle=False,  # No shuffling needed for testing\n",
    "    num_workers=4,  \n",
    "    pin_memory=True if device.type == 'cuda' else False,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "print(f\"Test batch count: {len(test_loader)}\")\n",
    "print(f\"Test loader using {test_loader.num_workers} workers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b47c3d",
   "metadata": {},
   "source": [
    "## Test Inference Configuration\n",
    "\n",
    "**Test Batch Size (64)**: Matches training batch size for consistency, though larger batches could be used during inference since no gradients are stored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdcde7f-2d97-4e31-94bd-2e848e13ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = COCOMultiLabelClassifier(num_classes=NUM_CLASSES, pretrained=False)\n",
    "\n",
    "if os.path.exists(MODEL_SAVE_PATH):\n",
    "    checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "    test_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Successfully loaded model weights from: {MODEL_SAVE_PATH}\")\n",
    "    print(f\"Model training epoch: {checkpoint['epoch']}\")\n",
    "    print(f\"Best validation loss: {checkpoint['best_val_micro_f1']:.4f}\")\n",
    "else:\n",
    "    print(f\"Trained model file not found: {MODEL_SAVE_PATH}\")\n",
    "    print(\"Please run the training program first\")\n",
    "    raise FileNotFoundError(f\"Model file not found: {MODEL_SAVE_PATH}\")\n",
    "\n",
    "test_model = test_model.to(device)\n",
    "test_model.eval()\n",
    "print(\"Model ready for inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2115528b-74b2-4301-b0e2-6702d872cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = {}\n",
    "print(\"Output dictionary initialized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff158e9",
   "metadata": {},
   "source": [
    "## Test Dataset and DataLoader Preparation\n",
    "\n",
    "**Transform Pipeline**:\n",
    "- **Identical to validation**: Same resize (224×224) and normalization to match training distribution\n",
    "- **No augmentation**: Uses deterministic transforms for consistent predictions\n",
    "\n",
    "**DataLoader Configuration**:\n",
    "- **No shuffling**: Preserves image order for result mapping\n",
    "- **4 workers**: Slightly reduced from training (6) as inference is less I/O bound\n",
    "- **Pin memory**: Enabled for faster CPU→GPU transfer\n",
    "- **Persistent workers**: Reduces overhead during iteration\n",
    "\n",
    "**Dataset Size**: 4952 test images → 78 batches with batch size 64.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83162c2-b3da-4812-a23a-2842f33cf670",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting prediction loop...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, filenames) in enumerate(tqdm(test_loader, desc=\"Predicting\")):\n",
    "        # Get mini-batch\n",
    "        images = images.to(device)\n",
    "        \n",
    "        outputs = test_model(images)\n",
    "        \n",
    "        probabilities = torch.sigmoid(outputs)\n",
    "        predictions = (probabilities > THRESHOLD).cpu().numpy()\n",
    "        \n",
    "        # Update dictionary entries, write corresponding class indices\n",
    "        for i, filename in enumerate(filenames):\n",
    "            predicted_classes = []\n",
    "            for class_idx in range(NUM_CLASSES):\n",
    "                if predictions[i, class_idx]:\n",
    "                    predicted_classes.append(class_idx)\n",
    "            \n",
    "            predictions_dict[filename] = predicted_classes\n",
    "\n",
    "print(f\"Prediction completed, processed {len(predictions_dict)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b9b418",
   "metadata": {},
   "source": [
    "## Model Loading for Inference\n",
    "\n",
    "**Loading Process**:\n",
    "1. **Initialize architecture**: Create model with random weights (`pretrained=False` to avoid downloading ImageNet weights)\n",
    "2. **Load checkpoint**: Retrieve saved state dictionary from training\n",
    "3. **Restore weights**: Apply trained parameters to model\n",
    "4. **Device placement**: Move to GPU for accelerated inference\n",
    "5. **Evaluation mode**: Disable dropout and batch normalization training behavior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fa075e-fd5d-4750-87f0-9d458b7f2093",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Saving prediction results to: {OUTPUT_JSON_FILE}\")\n",
    "\n",
    "# Show some sample predictions\n",
    "sample_count = 0\n",
    "for filename, predicted_classes in predictions_dict.items():\n",
    "    if sample_count < 5:  # Show only first 5 samples\n",
    "        print(f\"  Sample {filename}: predicted classes {predicted_classes}\")\n",
    "        sample_count += 1\n",
    "\n",
    "try:\n",
    "    with open(OUTPUT_JSON_FILE, 'w') as f:\n",
    "        json.dump(predictions_dict, f, indent=2)\n",
    "    print(f\"JSON file successfully saved to: {OUTPUT_JSON_FILE}\")\n",
    "    \n",
    "    # Check file size\n",
    "    file_size = os.path.getsize(OUTPUT_JSON_FILE)\n",
    "    print(f\"File size: {file_size / 1024:.2f} KB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error saving JSON file: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Test prediction program completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f63168",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
